{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    check if the data (zip) file is already downloaded\n",
    "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "tensorflow expect input with the argument, data_format. \"NHWC\": [batch, height, width, channels], \"NCHW\": [batch, channels, height, width].\n",
    "\n",
    "**reshape**\n",
    "1. 将行向量 (3072) 划分为 3 个片段. 每个片段对应一个channel.\n",
    "  - 结果为 (3 x 1024) 维度的tensor [3个channels]\n",
    "2. 划分每一个tensor为 32. 32 意味着图像的宽度（像素）\n",
    "  - 结果为 (3 x 32 x 32)(num_channel, width, height)\n",
    "  \n",
    "**transpose**\n",
    "1.  将(num_channel, width, height)转化为(width, height, num_channel)：\n",
    "  - 调用transpose(2,0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建字符串标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示数据\n",
    "1. batch_id: id for batch(1-5)\n",
    "2. sample_id: id for a image and label pair in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True))) \n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7001:\n",
      "Image - Min Value: 4 Max Value: 224\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 7001\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化Normalize\n",
    "1. Min-Max Normalization\n",
    "    - this simply makes all x values to range between 0 and 1.\n",
    "    - y = (x-min) / (max-min)\n",
    "2.  why normalization should be performed \n",
    "    - somewhat related to activation function.\n",
    "      -  sigmoid activation function takes an input value and outputs a new value ranging from 0 to 1.\n",
    "          - if input value is large, the output value easily reaches 1;\n",
    "          - if input small,output easily reaches 0\n",
    "      - ReLU activation function takes an input value and outputs a new value ranging from 0 to infinity.\n",
    "          - if input value is large, the output value increases linearly;\n",
    "          - if input small, output easily reaches 0\n",
    "3. All the image data originally ranges from 0 to 255.\n",
    "    - when it is passed into sigmoid function, the output is almost always 1\n",
    "    - when it is passed into ReLu function, the output could be very huge.\n",
    "    - When backpropagation process is performed to optimize the networks, this could lead to an exploding gradient which leads to an aweful learning steps. In order to avoid this issue, ideally, it is better let all the values be around 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot 编码\n",
    "1. CIFAR-10 提供10 个不同的类别，因此我们需要一个(10,)的向量，每个分量表示预测的类别，当分量为1是表示该图像对应的下标所表示的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集、检验集，读取测试集\n",
    "1. uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_test.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理输入的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y =  tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数\n",
    "1. `epochs`:\n",
    "2. `batch_size`\n",
    "3. `keep_probability`: 在dropout时留下一个node的概率\n",
    "4. `learning_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 #迭代次数\n",
    "batch_size = 128\n",
    "keep_probability = 0.7\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数和优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xsy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-14-a1c31b22992a>:13: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xsy\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-14-a1c31b22992a>:38: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-15-bc29ffa8bb57>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = conv_net(x, keep_prob)\n",
    "model = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示loss和accuracy的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据为batch_size个batches并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2239 Validation Accuracy: 0.175000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.8573 Validation Accuracy: 0.287400\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.4516 Validation Accuracy: 0.333200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.5382 Validation Accuracy: 0.419400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.4399 Validation Accuracy: 0.432400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.4149 Validation Accuracy: 0.512400\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.1134 Validation Accuracy: 0.488600\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.0644 Validation Accuracy: 0.548000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.1194 Validation Accuracy: 0.601200\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     0.9193 Validation Accuracy: 0.595400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     0.8715 Validation Accuracy: 0.617800\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     0.7199 Validation Accuracy: 0.635000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.4946 Validation Accuracy: 0.667600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     0.6322 Validation Accuracy: 0.680000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     0.5554 Validation Accuracy: 0.667600\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     0.5845 Validation Accuracy: 0.673000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.4791 Validation Accuracy: 0.676400\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.2630 Validation Accuracy: 0.685600\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.3558 Validation Accuracy: 0.718800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.2203 Validation Accuracy: 0.708200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     0.3510 Validation Accuracy: 0.700400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.2695 Validation Accuracy: 0.677200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.1400 Validation Accuracy: 0.697200\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.1476 Validation Accuracy: 0.709800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.1378 Validation Accuracy: 0.712800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.2072 Validation Accuracy: 0.710600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.1421 Validation Accuracy: 0.720600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.0920 Validation Accuracy: 0.701400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.1053 Validation Accuracy: 0.726400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.0598 Validation Accuracy: 0.717200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.1864 Validation Accuracy: 0.736200\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.0736 Validation Accuracy: 0.719600\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.0515 Validation Accuracy: 0.733400\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.0498 Validation Accuracy: 0.720400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.0323 Validation Accuracy: 0.731800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.0911 Validation Accuracy: 0.727200\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.0225 Validation Accuracy: 0.724800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.0354 Validation Accuracy: 0.730600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.0422 Validation Accuracy: 0.718000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.0109 Validation Accuracy: 0.729200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.0155 Validation Accuracy: 0.736600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.0160 Validation Accuracy: 0.734400\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.0123 Validation Accuracy: 0.715000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.0173 Validation Accuracy: 0.723800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.0078 Validation Accuracy: 0.731400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.0169 Validation Accuracy: 0.739000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.0254 Validation Accuracy: 0.730000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.0055 Validation Accuracy: 0.730400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.0136 Validation Accuracy: 0.737000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.0189 Validation Accuracy: 0.729800\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def display_image_predictions(features, labels, predictions, top_n_predictions):\n",
    "    n_classes = 10\n",
    "    label_names = load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=top_n_predictions, ncols=2, figsize=(20, 10))\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "   \n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        if (image_i < top_n_predictions):\n",
    "            print(imge_i)\n",
    "            pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "            correct_name = label_names[label_id]\n",
    "            \n",
    "            axies[image_i][0].imshow((feature*255).astype(np.int32, copy=False))\n",
    "            axies[image_i][0].set_title(correct_name)\n",
    "            axies[image_i][0].set_axis_off()\n",
    "\n",
    "            axies[image_i][1].barh(ind + margin, pred_values[:3], width)\n",
    "            axies[image_i][1].set_yticks(ind + margin)\n",
    "            axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "            axies[image_i][1].set_xticks([0, 0.5, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "batch_size = 64\n",
    "n_samples = 10\n",
    "top_n_predictions = 5\n",
    "\n",
    "def test_model():\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('input_x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('output_y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions, top_n_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████▊                 | 68223973761/100000000000 [5:32:11<3:04:58, 2862995.89it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "n=100000000000\n",
    "for i in tqdm(range(n)):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
